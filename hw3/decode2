#!/usr/bin/env python
import argparse
import sys
import models
import heapq
from collections import namedtuple
from copy import deepcopy

stacksize = 500
parser = argparse.ArgumentParser(description='Simple phrase based decoder.')
parser.add_argument('-i', '--input', dest='input', default='data/input', help='File containing sentences to translate (default=data/input)')
parser.add_argument('-t', '--translation-model', dest='tm', default='data/tm', help='File containing translation model (default=data/tm)')
parser.add_argument('-s', '--stack-size', dest='s', default=stacksize, type=int, help='Maximum stack size (default=1)')
parser.add_argument('-n', '--num_sentences', dest='num_sents', default=sys.maxint, type=int, help='Number of sentences to decode (default=no limit)')
parser.add_argument('-l', '--language-model', dest='lm', default='data/lm', help='File containing ARPA-format language model (default=data/lm)')
parser.add_argument('-v', '--verbose', dest='verbose', action='store_true', default=False,  help='Verbose mode (default=off)')
opts = parser.parse_args()

tm = models.TM(opts.tm, sys.maxint)
lm = models.LM(opts.lm)
sys.stderr.write('Decoding %s...\n' % (opts.input,))
input_sents = [tuple(line.strip().split()) for line in open(opts.input).readlines()[:opts.num_sents]]
#input_sent is a tuple of all spanish words
#input_sents is a list

hypothesis = namedtuple('hypothesis', 'logprob, lm_state, predecessor, phrase')
hypothesisNew = namedtuple('hypothesisNew', 'logprob, lm_state, predecessor, tranlist, phrase, start, end')

for f in input_sents:
    # The following code implements a DP monotone decoding
    # algorithm (one that doesn't permute the target phrases).
    # Hence all hypotheses in stacks[i] represent translations of 
    # the first i words of the input sentence.
    # HINT: Generalize this so that stacks[i] contains translations
    # of any i words (remember to keep track of which words those
    # are, and to estimate future costs)

    initial_hypothesis = hypothesis(0.0, lm.begin(), None, None)
    
    tranlist = [0] * len(f)
    initial_hypothesisNew = hypothesisNew(0.0, lm.begin(), None, tranlist, None, 0, 0)
    stacks = [{} for _ in f] + [{}]
    # create {} for every word + 1 in f
    
    stacks[0][lm.begin()] = initial_hypothesisNew
    reorderLimit = 6
    for i, stack in enumerate(stacks[:-1]):
        print "interation %d stack size is %d" % (i, len(stack))
        # extend the top s hypotheses in the current stack
        for h in heapq.nlargest(stacksize, stack.itervalues(), key=lambda h: h.logprob): # prune
            for intersize in xrange(1,4):
                for j in xrange(0,len(f)):
                    if h.tranlist[j:j+intersize] == [0]*intersize:
                        wordphrase = f[j:j+intersize]
                        #print wordphrase
                        if wordphrase in tm:
                            for phrase in tm[wordphrase]:
                                logprob = h.logprob + phrase.logprob
                                lm_state = h.lm_state
                                for word in phrase.english.split():
                                    (lm_state, word_logprob) = lm.score(lm_state, word)
                                    logprob += word_logprob
                                    newlist = deepcopy(h.tranlist)
                                    newlist[j:j+intersize] = [1]*intersize
                                    logprob += lm.end(lm_state) if newlist.count(1) == len(f) else 0.0
                                    new_hypothesis = hypothesisNew(logprob, lm_state, h, newlist, phrase, j, j+intersize)
                                    l = sorted([j, j+intersize, h.start, h.end])
                                if (l[2] - l[1] < reorderLimit):
                                    #check reorderlimit
                                    ones = newlist.count(1)
                                    if lm_state not in stacks[ones] or stacks[ones][lm_state].logprob < logprob: # second case is recombination
                                        stacks[ones][lm_state] = new_hypothesis 
                                        #print "newlist is", newlist
    # find best translation by looking at the best scoring hypothesis
    # on the last stack
    winner = max(stacks[-1].itervalues(), key=lambda h: h.logprob)
    def extract_english_recursive(h):
        return '' if h.predecessor is None else '%s%s ' % (extract_english_recursive(h.predecessor), h.phrase.english)
    print extract_english_recursive(winner)

    if opts.verbose:
        def extract_tm_logprob(h):
            return 0.0 if h.predecessor is None else h.phrase.logprob + extract_tm_logprob(h.predecessor)
        tm_logprob = extract_tm_logprob(winner)
        sys.stderr.write('LM = %f, TM = %f, Total = %f\n' % 
            (winner.logprob - tm_logprob, tm_logprob, winner.logprob))
